# ADPA实验复现步骤

## 环境信息
- 硬件：2张RTX Pro 6000 Blackwell GPU
- 初始教师模型：Mistral-7B-V0.1
- SFT数据集：HuggingFaceH4/deita-10k-v0-sft
- 偏好对齐数据集：argilla/dpo-mix-7k
- Conda环境：yun

## 阶段1：训练教师模型 - SFT训练（REF teacher）

### 命令：
```bash
cd ~/ADPA
CUDA_VISIBLE_DEVICES=0,1 \
ACCELERATE_LOG_LEVEL=info \
DS_SKIP_CUDA_CHECK=1 \
conda run -n yun python -m accelerate.commands.launch \
  --config_file recipes/accelerate_config/deepspeed_zero3_2gpu.yaml \
  scripts/run_sft.py \
  recipes/mistral-7b-deita/teacher_sft.yaml
```

### 预期输出：
- 模型保存在：`~/ADPA/data/mistral-7b-deita/ref_teacher`
- 训练3个epoch
- 使用2张GPU，有效batch size=128 (per_device=1, gradient_accumulation=64)

---

## 阶段2：训练教师模型 - DPO训练（DPO teacher）

### 前置条件：
- 阶段1完成，REF teacher模型已保存

### 命令：
```bash
cd ~/ADPA
CUDA_VISIBLE_DEVICES=0,1 \
ACCELERATE_LOG_LEVEL=info \
DS_SKIP_CUDA_CHECK=1 \
conda run -n yun python -m accelerate.commands.launch \
  --config_file recipes/accelerate_config/deepspeed_zero3_2gpu.yaml \
  scripts/run_distill_dpo.py \
  recipes/mistral-7b-deita/teacher_dpo.yaml
```

### 预期输出：
- 模型保存在：`~/ADPA/data/mistral-7b-deita/dpo_teacher`
- 训练1个epoch
- 每100步保存一次checkpoint

---

## 后续阶段将在前序阶段完成后继续...
